{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the parent directory into the path\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.data_loader import get_train_dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import pprint\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from src.models.model import ShapeClassifier\n",
    "\n",
    "from src.configs.model_config import ModelConfig\n",
    "# from src.data.data_loader import train_loader, num_classes\n",
    "# from src.utils.logs import writer\n",
    "from src.utils.train import train\n",
    "from src.utils.test import test\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    \"metric\": {\n",
    "        \"name\": 'accuracy',\n",
    "        \"goal\": 'maximize'\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        'learning_rate': {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 0.001\n",
    "        },\n",
    "        'batch_size': {\n",
    "            # integers between 32 and 256\n",
    "            # with evenly-distributed logarithms\n",
    "            'distribution': 'q_log_uniform_values',\n",
    "            'q': 8,\n",
    "            'min': 32,\n",
    "            'max': 256,\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [15, 20, 30]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd']\n",
    "        },\n",
    "        'fc_layer_size': {\n",
    "            'values': [128, 256, 512]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import get_train_dataset\n",
    "\n",
    "\n",
    "def build_dataset(batch_size):\n",
    "\n",
    "    return get_train_dataset(batch_size)\n",
    "\n",
    "\n",
    "def build_network(fc_layer_size):\n",
    "    network = ShapeClassifier(num_classes=3,hidden_size=fc_layer_size)\n",
    "\n",
    "    return network.to(device)\n",
    "\n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, loader, optimizer):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ➡ Forward pass\n",
    "        loss = F.cross_entropy(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"batch loss\": loss.item()})\n",
    "\n",
    "    return cumu_loss / len(loader)\n",
    "\n",
    "def validate(network, loader):\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    return correct / len(loader.dataset)\n",
    "    \n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run  \n",
    "\n",
    "    with wandb.init():\n",
    "        config = wandb.config\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        print(\"config\" , config)\n",
    "   \n",
    "        loader = build_dataset(config.batch_size)\n",
    "        network = build_network(config.fc_layer_size)\n",
    "        optimizer = build_optimizer(\n",
    "            network, config.optimizer, config.learning_rate)\n",
    "\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            avg_loss = train_epoch(network, loader, optimizer)\n",
    "            acc = validate(network, loader)\n",
    "            print(f\"Epoch {epoch} avg loss: {avg_loss} accuracy: {acc}\")\n",
    "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch, \"accuracy\": acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
